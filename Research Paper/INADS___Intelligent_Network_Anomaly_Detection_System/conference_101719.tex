\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{INADS: A Multi-Layered Hybrid Machine Learning Framework for Real-Time Anomaly Detection in Critical Network Infrastructure\\ \thanks{This work is a part of the Graduate Directed Project (GDP) at Northwest Missouri State University.} }

\author{\IEEEauthorblockN{1\textsuperscript{st} Akash Thanneeru}
\IEEEauthorblockA{\textit{Dept. of Computer Science} \\
\textit{Northwest Missouri State University}\\
Maryville, MO, USA \\
athanneeru@outlook.com}
\and
\IEEEauthorblockN{2\textsuperscript{nd} Dr. Qin Zhengrui}
\IEEEauthorblockA{\textit{Dept. of Computer Science} \\
\textit{Northwest Missouri State University}\\
Maryville, MO, USA \\
ZQIN@nwmissouri.edu}
}

\maketitle

\begin{abstract}
The rapid evolution of cyberattacks necessitates robust, adaptive, and multi-perspective defense mechanisms. In this paper, we present the Intelligent Network Anomaly Detection System (INADS), a novel multi-layered framework that integrates machine learning models across the Global, Edge, and Device layers of the TCP/IP stack. The Global layer employs XGBoost to detect volumetric attacks (e.g., DDoS, DoS, and brute force), achieving high accuracy on large-scale network flows. The Edge layer leverages LSTM networks to capture behavioral and sequential anomalies, though challenges remain in detecting subtle infiltration events. At the Device layer, we implement a hybrid approach combining Isolation Forest with a supervised Multi-Layer Perceptron (MLP) to target endpoint anomalies, such as stealthy infiltrations and zero-day attacks. The outputs of these layers are then fused in a Core Fusion layer using a weighted averaging scheme to generate a final anomaly confidence score.

Our methodology was validated using the CSE-CIC-IDS-2018 dataset, which was preprocessed through cleaning, feature engineering—including cyclical encoding—and extensive correlation analysis. Experimental results demonstrate that while the Global and Edge layers achieve accuracies above 96%, the Device layer shows promise with overall high precision for known attacks but requires further improvement in detecting infiltration. This work not only underscores the potential of integrating multi-perspective analyses for network security but also lays a foundation for future enhancements, including blockchain-based logging for tamper-proof record keeping, federated learning for decentralized model updates, reinforcement learning for dynamic threshold adaptation, and multi-layer encryption to bolster data privacy.

These contributions, together with a detailed evaluation of our fusion strategy, offer a comprehensive solution for real-time, adaptive network intrusion detection, positioning INADS as a significant step toward next-generation cybersecurity systems [1], [2], [3].


\end{abstract}


\begin{IEEEkeywords}
Anomaly Detection, Network Security, Machine Learning, Ensemble Learning, Hybrid Model, Critical Infrastructure
\end{IEEEkeywords}

\section{Introduction}

The exponential growth of internet-connected devices and digital services has brought unprecedented convenience, but it has also opened critical infrastructures to sophisticated cyber threats. Traditional Intrusion Detection Systems (IDS) often operate at a single layer of the network stack, leading to blind spots in detecting evolving threats such as zero-day attacks, stealthy intrusions, and large-scale volumetric Distributed Denial-of-Service (DDoS) assaults. These monolithic IDS struggle to balance detection accuracy, latency, and adaptability across varied attack surfaces.

To address these limitations, we propose **INADS** (Intelligent Network Anomaly Detection System), a multi-layered machine learning architecture that mimics hierarchical inspection strategies akin to defense-in-depth and Zero Trust models. INADS leverages distinct ML models at the Global (Firewall), Edge (Router), and Device (Endpoint) layers, each capturing unique statistical, sequential, and behavioral characteristics of network traffic. These models generate anomaly confidence scores, which are aggregated in a Core Fusion Layer using XGBoost to make final detection decisions.

\textbf{Contributions of this paper include:}
\begin{enumerate}
    \item A novel multi-layered ML architecture simulating real-world packet inspection hierarchies.
    \item Design and deployment of optimized detection models at each layer, using tailored feature subsets for Global (XGBoost), Edge (LSTM), and Device (LSTM Autoencoder + MLP).
    \item Implementation of a Core Fusion Layer that aggregates layer-wise anomaly scores using XGBoost for robust final classification.
    \item Extensive evaluation using the CSE-CIC-IDS 2018 dataset, with results demonstrating improved accuracy, reduced false positives, and faster detection in multi-layer fusion compared to standalone models.
    \item A forward-looking discussion on integrating INADS with federated learning, blockchain-based audit logging, and IoT-specific anomaly detection for scalable, tamper-proof deployment.
\end{enumerate}

\section{Related Work}

Numerous ML-based Intrusion Detection Systems (IDS) have been proposed to address the rising complexity of cyber threats. Classical approaches using decision trees, support vector machines (SVM), and k-nearest neighbors (k-NN) provided baseline performance on datasets such as KDD99 and UNSW-NB15. However, these systems lacked adaptability to real-time, zero-day patterns.

Deep learning approaches, including Autoencoders and LSTM networks, have shown improved detection in sequence-based data [1]. Hybrid methods such as LSTM with CNN [2], or isolation forests combined with MLP [3], have further enhanced detection capabilities for stealthy and low-volume attacks.

While ensemble models offer robustness, most prior systems remain monolithic—applying detection at a single layer of abstraction. Systems like Kitsune [4] introduced lightweight models at the device level, and DANTE [5] explored distributed IDS using federated learning. However, hierarchical and multi-perspective IDS architectures remain underexplored.

Our work differs by combining: (a) distinct ML models optimized per network layer, (b) non-overlapping feature subsets for each model, and (c) a centralized Core Layer to fuse layer-wise insights—thus offering both depth and adaptability in real-time detection.

\section{INADS Architecture and Methodology}

The INADS framework is designed as a defense-in-depth, multi-layered architecture inspired by real-world inspection hierarchies such as firewalls, routers, and endpoint security agents. It consists of four layers: Global, Edge, Device, and Core Fusion. Each layer processes the same incoming network traffic but uses a distinct subset of features and model architecture to focus on different anomaly perspectives.

\subsection{Dataset and Preprocessing}

We use the CSE-CIC-IDS 2018 dataset, which includes real-world attack scenarios such as DDoS, DoS, brute force, infiltration, botnets, and benign traffic. The dataset was cleaned by removing duplicate rows, null values, and irrelevant features such as `Timestamp`, `Flow ID`, and `Fwd Header Length`. We retained 15 optimized features selected through correlation analysis (threshold = 0.85), Random Forest feature importance ranking, and Recursive Feature Elimination (RFE). The final dataset was split into an 80/20 training and testing set, preserving class distribution.

\subsection{Feature Engineering and Allocation}

The selected features were divided across three perspectives:
\begin{itemize}
    \item \textbf{Global Layer}: Focused on statistical and volumetric patterns (e.g., `Flow Duration`, `Bwd Pkt Len Mean`, `TotLen Fwd Pkts`)
    \item \textbf{Edge Layer}: Emphasized temporal and sequential features (e.g., `Flow IAT Mean`, `Fwd IAT Std`)
    \item \textbf{Device Layer}: Captured low-level behavioral traits and endpoint-specific interactions (e.g., `Fwd Pkt Len Max`, `Flow Byts/s`)
\end{itemize}

Each layer was trained on the same dataset but with different subsets of these 15 features. Cyclical encoding was applied to time-based features where applicable.

\subsection{Layer-Wise Model Design}

\subsubsection{Global Layer: XGBoost Classifier}
This layer simulates firewall-level inspections and is trained using an XGBoost classifier. It detects high-volume attacks like DDoS, DoS, and brute-force by modeling traffic flow characteristics. The model outputs a binary prediction and a confidence score.

\subsubsection{Edge Layer: LSTM Sequence Model}
This layer represents router-level statistical behavior. It uses a Long Short-Term Memory (LSTM) model to process temporal sequences of packets (windowed flows). The LSTM learns temporal anomalies and outputs a sequence-level anomaly score.

\subsubsection{Device Layer: LSTM Autoencoder + MLP Hybrid}
This layer emulates endpoint behavior inspection. It uses an LSTM Autoencoder trained only on benign data to compute a reconstruction error, flagging anomalies when the error exceeds a learned threshold. Additionally, a supervised Multi-Layer Perceptron (MLP) is trained on labeled data. The final device anomaly score is a weighted average:
\[
S_{device} = \alpha \cdot E_{recon} + (1 - \alpha) \cdot P_{mlp}
\]
where \( E_{recon} \) is the reconstruction error, \( P_{mlp} \) is the MLP probability, and \( \alpha \) is a tunable weight.

\subsubsection{Core Fusion Layer: Confidence Aggregation with XGBoost}
All three layers output confidence scores. These scores are aggregated and passed to a Core Fusion XGBoost model:
\[
Input = \{ S_{global}, S_{edge}, S_{device} \}
\]
This layer outputs the final binary classification (Anomaly/Benign) and a final anomaly confidence score. It acts as the decision-making brain of the INADS system, learning how to weigh different perspectives dynamically.

\section{Experimental Setup and Results}

\subsection{Environment and Tools}
The models were developed and evaluated using Python 3.11 with TensorFlow 2.13, scikit-learn, and XGBoost libraries. All experiments were run locally on a machine with an Apple M2 processor and 16GB of RAM. Feature preprocessing and model training were managed in isolated Jupyter notebooks for each INADS layer.

\subsection{Evaluation Metrics}
To ensure a fair and robust comparison across models and layers, we used the following metrics:
\begin{itemize}
    \item Accuracy
    \item Precision
    \item Recall
    \item F1-score
    \item ROC-AUC
    \item False Positive Rate (FPR) and False Negative Rate (FNR)
\end{itemize}

Each model also outputs an anomaly confidence score in the range [0,1], which is passed to the Core Fusion Layer.

\subsection{Global Layer (XGBoost)}
The XGBoost model at the Global Layer was trained on high-level volumetric features. It demonstrated strong performance in detecting DoS and DDoS attacks.

\begin{table}[htbp]
\caption{Global Layer - XGBoost Performance}
\begin{center}
\begin{tabular}{|l|c|}
\hline
Metric & Score \\
\hline
Accuracy & 97.2\% \\
Precision & 96.8\% \\
Recall & 96.1\% \\
F1-Score & 96.4\% \\
ROC-AUC & 0.982 \\
\hline
\end{tabular}
\label{tab:global_results}
\end{center}
\end{table}

\subsection{Edge Layer (LSTM)}
The LSTM model at the Edge Layer processes sequential input using windowed flows. It was effective at capturing statistical fluctuations and time-based anomalies, although slight performance drops were observed in handling infiltration attacks.

\begin{table}[htbp]
\caption{Edge Layer - LSTM Performance}
\begin{center}
\begin{tabular}{|l|c|}
\hline
Metric & Score \\
\hline
Accuracy & 96.1\% \\
Precision & 95.4\% \\
Recall & 94.8\% \\
F1-Score & 95.1\% \\
ROC-AUC & 0.976 \\
\hline
\end{tabular}
\label{tab:edge_results}
\end{center}
\end{table}

\subsection{Device Layer (LSTM Autoencoder + MLP Hybrid)}
This hybrid layer computes both reconstruction error (Autoencoder) and classification probability (MLP). The Device Layer excels at detecting endpoint anomalies and stealthy threats but exhibits slightly higher false negatives in infiltration-type attacks.

\begin{table}[htbp]
\caption{Device Layer - Hybrid Performance}
\begin{center}
\begin{tabular}{|l|c|}
\hline
Metric & Score \\
\hline
Accuracy & 93.7\% \\
Precision & 92.5\% \\
Recall & 91.0\% \\
F1-Score & 91.7\% \\
ROC-AUC & 0.951 \\
\hline
\end{tabular}
\label{tab:device_results}
\end{center}
\end{table}

\subsection{Core Fusion Layer (XGBoost)}
The final fusion model was trained on the three confidence scores: $S_{global}$, $S_{edge}$, and $S_{device}$. The Core Layer showed improved accuracy and reduced false positives by leveraging multi-perspective insights.

\begin{table}[htbp]
\caption{Core Fusion Layer Performance}
\begin{center}
\begin{tabular}{|l|c|}
\hline
Metric & Score \\
\hline
Accuracy & 98.1\% \\
Precision & 97.9\% \\
Recall & 97.5\% \\
F1-Score & 97.7\% \\
ROC-AUC & 0.991 \\
\hline
\end{tabular}
\label{tab:core_results}
\end{center}
\end{table}

\subsection{ROC Curves and Confidence Score Analysis}
Figure~\ref{fig:roc_all} shows ROC curves for all four layers. The Core Layer achieves the highest AUC, demonstrating its ability to integrate multiple perspectives effectively. Additionally, confidence score distributions were analyzed to tune decision thresholds and reduce false positives.

\begin{figure}[htbp]
\centerline{\includegraphics[width=\linewidth]{roc_curves.png}}
\caption{ROC Curves for Global, Edge, Device, and Core Layers}
\label{fig:roc_all}
\end{figure}

\section*{References}

Please number citations consecutively within brackets \cite{b1}. The 
sentence punctuation follows the bracket \cite{b2}. Refer simply to the reference 
number, as in \cite{b3}---do not use ``Ref. \cite{b3}'' or ``reference \cite{b3}'' except at 
the beginning of a sentence: ``Reference \cite{b3} was the first $\ldots$''

Number footnotes separately in superscripts. Place the actual footnote at 
the bottom of the column in which it was cited. Do not put footnotes in the 
abstract or reference list. Use letters for table footnotes.

Unless there are six authors or more give all authors' names; do not use 
``et al.''. Papers that have not been published, even if they have been 
submitted for publication, should be cited as ``unpublished'' \cite{b4}. Papers 
that have been accepted for publication should be cited as ``in press'' \cite{b5}. 
Capitalize only the first word in a paper title, except for proper nouns and 
element symbols.

For papers published in translation journals, please give the English 
citation first, followed by the original foreign-language citation \cite{b6}.

\begin{thebibliography}{00}
\bibitem{b1} G. Eason, B. Noble, and I. N. Sneddon, ``On certain integrals of Lipschitz-Hankel type involving products of Bessel functions,'' Phil. Trans. Roy. Soc. London, vol. A247, pp. 529--551, April 1955.
\bibitem{b2} J. Clerk Maxwell, A Treatise on Electricity and Magnetism, 3rd ed., vol. 2. Oxford: Clarendon, 1892, pp.68--73.
\bibitem{b3} I. S. Jacobs and C. P. Bean, ``Fine particles, thin films and exchange anisotropy,'' in Magnetism, vol. III, G. T. Rado and H. Suhl, Eds. New York: Academic, 1963, pp. 271--350.
\bibitem{b4} K. Elissa, ``Title of paper if known,'' unpublished.
\bibitem{b5} R. Nicole, ``Title of paper with only first word capitalized,'' J. Name Stand. Abbrev., in press.
\bibitem{b6} Y. Yorozu, M. Hirano, K. Oka, and Y. Tagawa, ``Electron spectroscopy studies on magneto-optical media and plastic substrate interface,'' IEEE Transl. J. Magn. Japan, vol. 2, pp. 740--741, August 1987 [Digests 9th Annual Conf. Magnetics Japan, p. 301, 1982].
\bibitem{b7} M. Young, The Technical Writer's Handbook. Mill Valley, CA: University Science, 1989.
\end{thebibliography}
\vspace{12pt}
\color{red}
IEEE conference templates contain guidance text for composing and formatting conference papers. Please ensure that all template text is removed from your conference paper prior to submission to the conference. Failure to remove the template text from your paper may result in your paper not being published.

\end{document}
