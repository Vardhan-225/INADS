{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9308dff3-d52e-4de7-8adc-023f40d8478b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking Labels in Individual Files Before Merging...\n",
      "\n",
      "‚úÖ C:\\Users\\S569652\\Documents\\INADS\\data\\benign\\Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv:\n",
      "Label\n",
      "Benign           544200\n",
      "Infilteration     68871\n",
      "Label                33\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úÖ C:\\Users\\S569652\\Documents\\INADS\\data\\ddos\\DoS_Attacks_Filtered.csv:\n",
      "Label\n",
      "DoS attacks-GoldenEye    41508\n",
      "DoS attacks-Slowloris    10990\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úÖ C:\\Users\\S569652\\Documents\\INADS\\data\\ddos\\Friday-16-02-2018_TrafficForML_CICFlowMeter.csv:\n",
      "Label\n",
      "DDoS attacks-LOIC-HTTP    576191\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úÖ C:\\Users\\S569652\\Documents\\INADS\\data\\mixed_attacks\\Friday-23-02-2018_TrafficForML_CICFlowMeter.csv:\n",
      "Label\n",
      "Benign              1048009\n",
      "Brute Force -Web        362\n",
      "Brute Force -XSS        151\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of dataset file paths to check shape of the dataset\n",
    "file_paths = [\n",
    "    r\"C:\\Users\\S569652\\Documents\\INADS\\data\\benign\\Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv\",\n",
    "    r\"C:\\Users\\S569652\\Documents\\INADS\\data\\ddos\\DoS_Attacks_Filtered.csv\",\n",
    "    r\"C:\\Users\\S569652\\Documents\\INADS\\data\\ddos\\Friday-16-02-2018_TrafficForML_CICFlowMeter.csv\",\n",
    "    r\"C:\\Users\\S569652\\Documents\\INADS\\data\\mixed_attacks\\Friday-23-02-2018_TrafficForML_CICFlowMeter.csv\",\n",
    "]\n",
    "\n",
    "# Check attack label counts in each file\n",
    "print(\"üîç Checking Labels in Individual Files Before Merging...\\n\")\n",
    "pre_merge_labels = {}\n",
    "\n",
    "for file in file_paths:\n",
    "    df = pd.read_csv(file, usecols=['Label'], dtype=str)  # Ensure 'Label' column is read properly\n",
    "    label_counts = df['Label'].value_counts()\n",
    "    pre_merge_labels[file] = label_counts\n",
    "    print(f\"‚úÖ {file}:\\n{label_counts}\\n\")\n",
    "\n",
    "# Store unique labels found across all datasets\n",
    "unique_labels_before = set()\n",
    "for labels in pre_merge_labels.values():\n",
    "    unique_labels_before.update(labels.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "268d0579-897a-43e6-a198-5b8cebe49288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ C:\\Users\\S569652\\Documents\\INADS\\data\\benign\\Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv: 80 columns\n",
      "‚úÖ C:\\Users\\S569652\\Documents\\INADS\\data\\ddos\\DoS_Attacks_Filtered.csv: 80 columns\n",
      "‚úÖ C:\\Users\\S569652\\Documents\\INADS\\data\\ddos\\Friday-16-02-2018_TrafficForML_CICFlowMeter.csv: 80 columns\n",
      "‚úÖ C:\\Users\\S569652\\Documents\\INADS\\data\\mixed_attacks\\Friday-23-02-2018_TrafficForML_CICFlowMeter.csv: 80 columns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of dataset file paths\n",
    "file_paths = [\n",
    "    r\"C:\\Users\\S569652\\Documents\\INADS\\data\\benign\\Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv\",\n",
    "    r\"C:\\Users\\S569652\\Documents\\INADS\\data\\ddos\\DoS_Attacks_Filtered.csv\",\n",
    "    r\"C:\\Users\\S569652\\Documents\\INADS\\data\\ddos\\Friday-16-02-2018_TrafficForML_CICFlowMeter.csv\",\n",
    "    r\"C:\\Users\\S569652\\Documents\\INADS\\data\\mixed_attacks\\Friday-23-02-2018_TrafficForML_CICFlowMeter.csv\"\n",
    "]\n",
    "\n",
    "# Store column structures\n",
    "columns_dict = {}\n",
    "\n",
    "for file in file_paths:\n",
    "    df = pd.read_csv(file, nrows=5, low_memory=False)  # Load small portion to check structure\n",
    "    columns_dict[file] = set(df.columns)\n",
    "    print(f\"‚úÖ {file}: {len(df.columns)} columns\")\n",
    "\n",
    "# Compare all column names\n",
    "common_cols = set.intersection(*columns_dict.values())\n",
    "for file, cols in columns_dict.items():\n",
    "    extra_cols = cols - common_cols\n",
    "    missing_cols = common_cols - cols\n",
    "    if extra_cols or missing_cols:\n",
    "        print(f\"‚ö†Ô∏è {file}: Extra Columns: {extra_cols} | Missing Columns: {missing_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3e04657-3e0c-460c-b050-59d2c373b270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ C:\\Users\\S569652\\Documents\\INADS\\data\\benign\\Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv: \n",
      "Label\n",
      "Benign           544200\n",
      "Infilteration     68871\n",
      "Label                33\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úÖ C:\\Users\\S569652\\Documents\\INADS\\data\\ddos\\DoS_Attacks_Filtered.csv: \n",
      "Label\n",
      "DoS attacks-GoldenEye    41508\n",
      "DoS attacks-Slowloris    10990\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úÖ C:\\Users\\S569652\\Documents\\INADS\\data\\ddos\\Friday-16-02-2018_TrafficForML_CICFlowMeter.csv: \n",
      "Label\n",
      "DDoS attacks-LOIC-HTTP    576191\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úÖ C:\\Users\\S569652\\Documents\\INADS\\data\\mixed_attacks\\Friday-23-02-2018_TrafficForML_CICFlowMeter.csv: \n",
      "Label\n",
      "Benign              1048009\n",
      "Brute Force -Web        362\n",
      "Brute Force -XSS        151\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in file_paths:\n",
    "    df = pd.read_csv(file, usecols=['Label'], low_memory=False)\n",
    "    label_counts = df['Label'].value_counts()\n",
    "    print(f\"‚úÖ {file}: \\n{label_counts}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "effec1af-0017-472c-86a0-d6456223b7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ C:\\Users\\S569652\\Documents\\INADS\\data\\benign\\Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv: Missing Values\n",
      "Dst Port         0\n",
      "Protocol         0\n",
      "Timestamp        0\n",
      "Flow Duration    0\n",
      "Tot Fwd Pkts     0\n",
      "                ..\n",
      "Idle Mean        0\n",
      "Idle Std         0\n",
      "Idle Max         0\n",
      "Idle Min         0\n",
      "Label            0\n",
      "Length: 80, dtype: int64\n",
      "\n",
      "‚úÖ C:\\Users\\S569652\\Documents\\INADS\\data\\ddos\\DoS_Attacks_Filtered.csv: Missing Values\n",
      "Dst Port         0\n",
      "Protocol         0\n",
      "Timestamp        0\n",
      "Flow Duration    0\n",
      "Tot Fwd Pkts     0\n",
      "                ..\n",
      "Idle Mean        0\n",
      "Idle Std         0\n",
      "Idle Max         0\n",
      "Idle Min         0\n",
      "Label            0\n",
      "Length: 80, dtype: int64\n",
      "\n",
      "‚úÖ C:\\Users\\S569652\\Documents\\INADS\\data\\ddos\\Friday-16-02-2018_TrafficForML_CICFlowMeter.csv: Missing Values\n",
      "Dst Port         0\n",
      "Protocol         0\n",
      "Timestamp        0\n",
      "Flow Duration    0\n",
      "Tot Fwd Pkts     0\n",
      "                ..\n",
      "Idle Mean        0\n",
      "Idle Std         0\n",
      "Idle Max         0\n",
      "Idle Min         0\n",
      "Label            0\n",
      "Length: 80, dtype: int64\n",
      "\n",
      "‚úÖ C:\\Users\\S569652\\Documents\\INADS\\data\\mixed_attacks\\Friday-23-02-2018_TrafficForML_CICFlowMeter.csv: Missing Values\n",
      "Dst Port         0\n",
      "Protocol         0\n",
      "Timestamp        0\n",
      "Flow Duration    0\n",
      "Tot Fwd Pkts     0\n",
      "                ..\n",
      "Idle Mean        0\n",
      "Idle Std         0\n",
      "Idle Max         0\n",
      "Idle Min         0\n",
      "Label            0\n",
      "Length: 80, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in file_paths:\n",
    "    df = pd.read_csv(file, low_memory=False)\n",
    "    print(f\"‚úÖ {file}: Missing Values\\n{df.isnull().sum()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9387b6a-eda2-4aab-907d-f58815791856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Merging: C:\\Users\\S569652\\Documents\\INADS\\data\\benign\\Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "‚úÖ Merging: C:\\Users\\S569652\\Documents\\INADS\\data\\ddos\\DoS_Attacks_Filtered.csv\n",
      "‚úÖ Merging: C:\\Users\\S569652\\Documents\\INADS\\data\\ddos\\Friday-16-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "‚úÖ Merging: C:\\Users\\S569652\\Documents\\INADS\\data\\mixed_attacks\\Friday-23-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "‚úÖ Merged dataset saved at: C:\\Users\\S569652\\Documents\\INADS\\data\\Merged-Dataset.csv\n",
      "\n",
      "üîç Final Label Distribution After Merging:\n",
      "Label\n",
      "Benign                    1592209\n",
      "DDoS attacks-LOIC-HTTP     576191\n",
      "Infilteration               68871\n",
      "DoS attacks-GoldenEye       41508\n",
      "DoS attacks-Slowloris       10990\n",
      "Brute Force -Web              362\n",
      "Brute Force -XSS              151\n",
      "Label                          33\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of dataset file paths\n",
    "file_paths = [\n",
    "    r\"C:\\Users\\S569652\\Documents\\INADS\\data\\benign\\Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv\",\n",
    "    r\"C:\\Users\\S569652\\Documents\\INADS\\data\\ddos\\DoS_Attacks_Filtered.csv\",\n",
    "    r\"C:\\Users\\S569652\\Documents\\INADS\\data\\ddos\\Friday-16-02-2018_TrafficForML_CICFlowMeter.csv\",\n",
    "    r\"C:\\Users\\S569652\\Documents\\INADS\\data\\mixed_attacks\\Friday-23-02-2018_TrafficForML_CICFlowMeter.csv\"\n",
    "]\n",
    "\n",
    "# Output file for the merged dataset\n",
    "output_file = r\"C:\\Users\\S569652\\Documents\\INADS\\data\\Merged-Dataset.csv\"\n",
    "\n",
    "# Define chunk size to process data efficiently\n",
    "chunk_size = 100000  # Load 100,000 rows at a time\n",
    "first_chunk = True   # Flag to ensure header is written only once\n",
    "\n",
    "# Merge and write in chunks\n",
    "for file in file_paths:\n",
    "    print(f\"‚úÖ Merging: {file}\")\n",
    "    for chunk in pd.read_csv(file, chunksize=chunk_size, low_memory=False):\n",
    "        chunk.to_csv(output_file, mode='a', header=first_chunk, index=False)\n",
    "        first_chunk = False  # Only write header for the first file\n",
    "\n",
    "print(f\"‚úÖ Merged dataset saved at: {output_file}\")\n",
    "\n",
    "# ‚úÖ Load merged dataset for final verification\n",
    "df = pd.read_csv(output_file, usecols=['Label'], low_memory=False)\n",
    "print(\"\\nüîç Final Label Distribution After Merging:\")\n",
    "print(df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91446eb5-fe15-4cb0-b900-9881f7de0fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S569652\\AppData\\Local\\Temp\\ipykernel_13672\\1866599514.py:5: DtypeWarning: Columns (0,1,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2290315 entries, 0 to 2290314\n",
      "Data columns (total 80 columns):\n",
      " #   Column             Dtype \n",
      "---  ------             ----- \n",
      " 0   Dst Port           object\n",
      " 1   Protocol           object\n",
      " 2   Timestamp          object\n",
      " 3   Flow Duration      object\n",
      " 4   Tot Fwd Pkts       object\n",
      " 5   Tot Bwd Pkts       object\n",
      " 6   TotLen Fwd Pkts    object\n",
      " 7   TotLen Bwd Pkts    object\n",
      " 8   Fwd Pkt Len Max    object\n",
      " 9   Fwd Pkt Len Min    object\n",
      " 10  Fwd Pkt Len Mean   object\n",
      " 11  Fwd Pkt Len Std    object\n",
      " 12  Bwd Pkt Len Max    object\n",
      " 13  Bwd Pkt Len Min    object\n",
      " 14  Bwd Pkt Len Mean   object\n",
      " 15  Bwd Pkt Len Std    object\n",
      " 16  Flow Byts/s        object\n",
      " 17  Flow Pkts/s        object\n",
      " 18  Flow IAT Mean      object\n",
      " 19  Flow IAT Std       object\n",
      " 20  Flow IAT Max       object\n",
      " 21  Flow IAT Min       object\n",
      " 22  Fwd IAT Tot        object\n",
      " 23  Fwd IAT Mean       object\n",
      " 24  Fwd IAT Std        object\n",
      " 25  Fwd IAT Max        object\n",
      " 26  Fwd IAT Min        object\n",
      " 27  Bwd IAT Tot        object\n",
      " 28  Bwd IAT Mean       object\n",
      " 29  Bwd IAT Std        object\n",
      " 30  Bwd IAT Max        object\n",
      " 31  Bwd IAT Min        object\n",
      " 32  Fwd PSH Flags      object\n",
      " 33  Bwd PSH Flags      object\n",
      " 34  Fwd URG Flags      object\n",
      " 35  Bwd URG Flags      object\n",
      " 36  Fwd Header Len     object\n",
      " 37  Bwd Header Len     object\n",
      " 38  Fwd Pkts/s         object\n",
      " 39  Bwd Pkts/s         object\n",
      " 40  Pkt Len Min        object\n",
      " 41  Pkt Len Max        object\n",
      " 42  Pkt Len Mean       object\n",
      " 43  Pkt Len Std        object\n",
      " 44  Pkt Len Var        object\n",
      " 45  FIN Flag Cnt       object\n",
      " 46  SYN Flag Cnt       object\n",
      " 47  RST Flag Cnt       object\n",
      " 48  PSH Flag Cnt       object\n",
      " 49  ACK Flag Cnt       object\n",
      " 50  URG Flag Cnt       object\n",
      " 51  CWE Flag Count     object\n",
      " 52  ECE Flag Cnt       object\n",
      " 53  Down/Up Ratio      object\n",
      " 54  Pkt Size Avg       object\n",
      " 55  Fwd Seg Size Avg   object\n",
      " 56  Bwd Seg Size Avg   object\n",
      " 57  Fwd Byts/b Avg     object\n",
      " 58  Fwd Pkts/b Avg     object\n",
      " 59  Fwd Blk Rate Avg   object\n",
      " 60  Bwd Byts/b Avg     object\n",
      " 61  Bwd Pkts/b Avg     object\n",
      " 62  Bwd Blk Rate Avg   object\n",
      " 63  Subflow Fwd Pkts   object\n",
      " 64  Subflow Fwd Byts   object\n",
      " 65  Subflow Bwd Pkts   object\n",
      " 66  Subflow Bwd Byts   object\n",
      " 67  Init Fwd Win Byts  object\n",
      " 68  Init Bwd Win Byts  object\n",
      " 69  Fwd Act Data Pkts  object\n",
      " 70  Fwd Seg Size Min   object\n",
      " 71  Active Mean        object\n",
      " 72  Active Std         object\n",
      " 73  Active Max         object\n",
      " 74  Active Min         object\n",
      " 75  Idle Mean          object\n",
      " 76  Idle Std           object\n",
      " 77  Idle Max           object\n",
      " 78  Idle Min           object\n",
      " 79  Label              object\n",
      "dtypes: object(80)\n",
      "memory usage: 1.4+ GB\n",
      "None\n",
      "\n",
      "üîç First Few Rows:\n",
      "  Dst Port Protocol            Timestamp Flow Duration Tot Fwd Pkts  \\\n",
      "0      443        6  28/02/2018 08:22:13         94658            6   \n",
      "1      443        6  28/02/2018 08:22:13           206            2   \n",
      "2      445        6  28/02/2018 08:22:15        165505            3   \n",
      "3      443        6  28/02/2018 08:22:16        102429            6   \n",
      "4      443        6  28/02/2018 08:22:16           167            2   \n",
      "\n",
      "  Tot Bwd Pkts TotLen Fwd Pkts TotLen Bwd Pkts Fwd Pkt Len Max  \\\n",
      "0            7             708            3718             387   \n",
      "1            0               0               0               0   \n",
      "2            1               0               0               0   \n",
      "3            7             708            3718             387   \n",
      "4            0               0               0               0   \n",
      "\n",
      "  Fwd Pkt Len Min  ... Fwd Seg Size Min Active Mean Active Std Active Max  \\\n",
      "0               0  ...               20         0.0        0.0          0   \n",
      "1               0  ...               20         0.0        0.0          0   \n",
      "2               0  ...               20         0.0        0.0          0   \n",
      "3               0  ...               20         0.0        0.0          0   \n",
      "4               0  ...               20         0.0        0.0          0   \n",
      "\n",
      "  Active Min Idle Mean Idle Std Idle Max Idle Min   Label  \n",
      "0          0       0.0      0.0        0        0  Benign  \n",
      "1          0       0.0      0.0        0        0  Benign  \n",
      "2          0       0.0      0.0        0        0  Benign  \n",
      "3          0       0.0      0.0        0        0  Benign  \n",
      "4          0       0.0      0.0        0        0  Benign  \n",
      "\n",
      "[5 rows x 80 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the merged dataset\n",
    "file_path = r\"C:\\Users\\S569652\\Documents\\INADS\\data\\Merged-Dataset.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display basic dataset info\n",
    "print(\"üîç Dataset Info:\")\n",
    "print(df.info())  # Checks for data types, missing values, and memory usage\n",
    "\n",
    "print(\"\\nüîç First Few Rows:\")\n",
    "print(df.head())  # Displays first few rows to check overall structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8a05cb2-1754-4ec7-b76d-07b3dfa15b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully converted 78 columns to numeric.\n",
      "‚ö†Ô∏è Columns that still have issues: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reload dataset (ensure low_memory=False)\n",
    "file_path = r\"C:\\Users\\S569652\\Documents\\INADS\\data\\Merged-Dataset.csv\"\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# Detect numeric columns that should NOT be objects\n",
    "numeric_columns = [col for col in df.columns if col not in ['Timestamp', 'Label']]\n",
    "problematic_columns = []\n",
    "\n",
    "for col in numeric_columns:\n",
    "    try:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error converting {col}: {e}\")\n",
    "        problematic_columns.append(col)\n",
    "\n",
    "print(f\"‚úÖ Successfully converted {len(numeric_columns) - len(problematic_columns)} columns to numeric.\")\n",
    "print(f\"‚ö†Ô∏è Columns that still have issues: {problematic_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd38d8cf-8240-4d46-ac92-f3286fd78c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleaned dataset saved at: C:\\Users\\S569652\\Documents\\INADS\\data\\Merged-Dataset-Cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "cleaned_path = r\"C:\\Users\\S569652\\Documents\\INADS\\data\\Merged-Dataset-Cleaned.csv\"\n",
    "df.to_csv(cleaned_path, index=False)\n",
    "print(f\"‚úÖ Cleaned dataset saved at: {cleaned_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "436fece1-6eee-4898-bff6-78544477fb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset Shape: (2290315, 80)\n",
      "‚úÖ Column Count: 80\n",
      "üîç Missing Values per Column:\n",
      "10369\n",
      "üîç Data Types Summary:\n",
      "float64    78\n",
      "object      2\n",
      "Name: count, dtype: int64\n",
      "üîç Final Label Distribution After Cleaning:\n",
      "\n",
      "Label\n",
      "Benign                    1592209\n",
      "DDoS attacks-LOIC-HTTP     576191\n",
      "Infilteration               68871\n",
      "DoS attacks-GoldenEye       41508\n",
      "DoS attacks-Slowloris       10990\n",
      "Brute Force -Web              362\n",
      "Brute Force -XSS              151\n",
      "Label                          33\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load cleaned dataset\n",
    "cleaned_file_path = r\"C:\\Users\\S569652\\Documents\\INADS\\data\\Merged-Dataset-Cleaned.csv\"\n",
    "df = pd.read_csv(cleaned_file_path)\n",
    "\n",
    "# üîç 1. Verify column count\n",
    "print(f\"‚úÖ Dataset Shape: {df.shape}\")\n",
    "print(\"‚úÖ Column Count:\", len(df.columns))\n",
    "\n",
    "# üîç 2. Check missing values\n",
    "print(\"üîç Missing Values per Column:\")\n",
    "print(df.isnull().sum().sum())\n",
    "\n",
    "# üîç 3. Ensure all numerical columns are converted correctly\n",
    "print(\"üîç Data Types Summary:\")\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "# üîç 4. Check final label distribution\n",
    "print(\"üîç Final Label Distribution After Cleaning:\\n\")\n",
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "811be837-941e-48d5-b4de-792b162fb195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Columns with Missing Values:\n",
      "\n",
      "Dst Port         33\n",
      "Protocol         33\n",
      "Flow Duration    33\n",
      "Tot Fwd Pkts     33\n",
      "Tot Bwd Pkts     33\n",
      "                 ..\n",
      "Active Min       33\n",
      "Idle Mean        33\n",
      "Idle Std         33\n",
      "Idle Max         33\n",
      "Idle Min         33\n",
      "Length: 78, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"üîç Columns with Missing Values:\\n\")\n",
    "print(df.isnull().sum()[df.isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b008d4bf-0b68-4c66-a682-93ad80e47ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Dst Port  Protocol            Timestamp  Flow Duration  Tot Fwd Pkts  \\\n",
      "6         49688.0       6.0  28/02/2018 08:22:21            0.0           2.0   \n",
      "138       49749.0       6.0  28/02/2018 08:29:33            0.0           2.0   \n",
      "162       49753.0       6.0  28/02/2018 08:29:37            0.0           2.0   \n",
      "163       49767.0       6.0  28/02/2018 08:29:37            0.0           2.0   \n",
      "246       49836.0       6.0  28/02/2018 08:34:05            0.0           2.0   \n",
      "...           ...       ...                  ...            ...           ...   \n",
      "2285565   50632.0       6.0  23/02/2018 11:53:30            0.0           2.0   \n",
      "2286474   52042.0       6.0  23/02/2018 03:34:08            0.0           2.0   \n",
      "2287538   52102.0       6.0  23/02/2018 03:43:01            0.0           2.0   \n",
      "2288132   49491.0       6.0  23/02/2018 08:17:04            0.0           2.0   \n",
      "2288411   50894.0       6.0  23/02/2018 12:15:28            0.0           2.0   \n",
      "\n",
      "         Tot Bwd Pkts  TotLen Fwd Pkts  TotLen Bwd Pkts  Fwd Pkt Len Max  \\\n",
      "6                 0.0              0.0              0.0              0.0   \n",
      "138               0.0              0.0              0.0              0.0   \n",
      "162               0.0              0.0              0.0              0.0   \n",
      "163               0.0              0.0              0.0              0.0   \n",
      "246               0.0              0.0              0.0              0.0   \n",
      "...               ...              ...              ...              ...   \n",
      "2285565           0.0              0.0              0.0              0.0   \n",
      "2286474           0.0              0.0              0.0              0.0   \n",
      "2287538           0.0              0.0              0.0              0.0   \n",
      "2288132           0.0              0.0              0.0              0.0   \n",
      "2288411           0.0              0.0              0.0              0.0   \n",
      "\n",
      "         Fwd Pkt Len Min  ...  Fwd Seg Size Min  Active Mean  Active Std  \\\n",
      "6                    0.0  ...              20.0          0.0         0.0   \n",
      "138                  0.0  ...              20.0          0.0         0.0   \n",
      "162                  0.0  ...              20.0          0.0         0.0   \n",
      "163                  0.0  ...              20.0          0.0         0.0   \n",
      "246                  0.0  ...              20.0          0.0         0.0   \n",
      "...                  ...  ...               ...          ...         ...   \n",
      "2285565              0.0  ...              20.0          0.0         0.0   \n",
      "2286474              0.0  ...              20.0          0.0         0.0   \n",
      "2287538              0.0  ...              20.0          0.0         0.0   \n",
      "2288132              0.0  ...              20.0          0.0         0.0   \n",
      "2288411              0.0  ...              20.0          0.0         0.0   \n",
      "\n",
      "         Active Max  Active Min  Idle Mean  Idle Std  Idle Max  Idle Min  \\\n",
      "6               0.0         0.0        0.0       0.0       0.0       0.0   \n",
      "138             0.0         0.0        0.0       0.0       0.0       0.0   \n",
      "162             0.0         0.0        0.0       0.0       0.0       0.0   \n",
      "163             0.0         0.0        0.0       0.0       0.0       0.0   \n",
      "246             0.0         0.0        0.0       0.0       0.0       0.0   \n",
      "...             ...         ...        ...       ...       ...       ...   \n",
      "2285565         0.0         0.0        0.0       0.0       0.0       0.0   \n",
      "2286474         0.0         0.0        0.0       0.0       0.0       0.0   \n",
      "2287538         0.0         0.0        0.0       0.0       0.0       0.0   \n",
      "2288132         0.0         0.0        0.0       0.0       0.0       0.0   \n",
      "2288411         0.0         0.0        0.0       0.0       0.0       0.0   \n",
      "\n",
      "          Label  \n",
      "6        Benign  \n",
      "138      Benign  \n",
      "162      Benign  \n",
      "163      Benign  \n",
      "246      Benign  \n",
      "...         ...  \n",
      "2285565  Benign  \n",
      "2286474  Benign  \n",
      "2287538  Benign  \n",
      "2288132  Benign  \n",
      "2288411  Benign  \n",
      "\n",
      "[7828 rows x 80 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df[df.isnull().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0e3766f-8b83-49aa-a627-a58e9eb0141e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Removed rows with zero Flow Duration.\n"
     ]
    }
   ],
   "source": [
    "df = df[df[\"Flow Duration\"] != 0]\n",
    "print(\"‚úÖ Removed rows with zero Flow Duration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45f26a41-25e6-4dfc-8bec-7771156b03d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Missing Values After Cleanup:\n",
      " 2574\n"
     ]
    }
   ],
   "source": [
    "print(\"üîç Missing Values After Cleanup:\\n\", df.isnull().sum().sum())  # Should return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d116f91-e54e-4ee9-99dd-09c459f9c61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Columns with Remaining Missing Values:\n",
      " Dst Port         33\n",
      "Protocol         33\n",
      "Flow Duration    33\n",
      "Tot Fwd Pkts     33\n",
      "Tot Bwd Pkts     33\n",
      "                 ..\n",
      "Active Min       33\n",
      "Idle Mean        33\n",
      "Idle Std         33\n",
      "Idle Max         33\n",
      "Idle Min         33\n",
      "Length: 78, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(\"üîç Columns with Remaining Missing Values:\\n\", missing_values[missing_values > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e10ef655-01e7-4635-9bcf-42bfa2331748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Dst Port  Protocol  Timestamp  Flow Duration  Tot Fwd Pkts  \\\n",
      "21838        NaN       NaN  Timestamp            NaN           NaN   \n",
      "43117        NaN       NaN  Timestamp            NaN           NaN   \n",
      "63291        NaN       NaN  Timestamp            NaN           NaN   \n",
      "84013        NaN       NaN  Timestamp            NaN           NaN   \n",
      "107719       NaN       NaN  Timestamp            NaN           NaN   \n",
      "\n",
      "        Tot Bwd Pkts  TotLen Fwd Pkts  TotLen Bwd Pkts  Fwd Pkt Len Max  \\\n",
      "21838            NaN              NaN              NaN              NaN   \n",
      "43117            NaN              NaN              NaN              NaN   \n",
      "63291            NaN              NaN              NaN              NaN   \n",
      "84013            NaN              NaN              NaN              NaN   \n",
      "107719           NaN              NaN              NaN              NaN   \n",
      "\n",
      "        Fwd Pkt Len Min  ...  Fwd Seg Size Min  Active Mean  Active Std  \\\n",
      "21838               NaN  ...               NaN          NaN         NaN   \n",
      "43117               NaN  ...               NaN          NaN         NaN   \n",
      "63291               NaN  ...               NaN          NaN         NaN   \n",
      "84013               NaN  ...               NaN          NaN         NaN   \n",
      "107719              NaN  ...               NaN          NaN         NaN   \n",
      "\n",
      "        Active Max  Active Min  Idle Mean  Idle Std  Idle Max  Idle Min  Label  \n",
      "21838          NaN         NaN        NaN       NaN       NaN       NaN  Label  \n",
      "43117          NaN         NaN        NaN       NaN       NaN       NaN  Label  \n",
      "63291          NaN         NaN        NaN       NaN       NaN       NaN  Label  \n",
      "84013          NaN         NaN        NaN       NaN       NaN       NaN  Label  \n",
      "107719         NaN         NaN        NaN       NaN       NaN       NaN  Label  \n",
      "\n",
      "[5 rows x 80 columns]\n",
      "üîç Total Rows with Missing Values: 33\n"
     ]
    }
   ],
   "source": [
    "df_missing = df[df.isnull().any(axis=1)]\n",
    "print(df_missing.head())\n",
    "print(f\"üîç Total Rows with Missing Values: {len(df_missing)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4c48ba7d-80f5-44d3-a26b-cafc77605fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Removed all rows with missing values.\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "print(\"‚úÖ Removed all rows with missing values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb0e29a8-275b-4840-a22e-fc5516f97515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Missing Values After Cleanup: 0\n"
     ]
    }
   ],
   "source": [
    "missing_values_after = df.isnull().sum().sum()\n",
    "print(f\"üîç Missing Values After Cleanup: {missing_values_after}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e42111b-daac-4618-8166-7f409c453b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Final cleaned dataset saved successfully!\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"C:\\\\Users\\\\S569652\\\\Documents\\\\INADS\\\\data\\\\Merged-Dataset-Final.csv\", index=False)\n",
    "print(\"‚úÖ Final cleaned dataset saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6c31559-7c63-4c86-908e-2e675695912f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Dataset Overview\n",
      "Shape: (2278405, 80)\n",
      "Total Columns: 80\n",
      "\n",
      "üîç Data Types Summary:\n",
      " float64    78\n",
      "object      2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úÖ No Missing Values Found!\n",
      "\n",
      "üîç Final Label Distribution:\n",
      "Label\n",
      "Benign                    1580967\n",
      "DDoS attacks-LOIC-HTTP     576191\n",
      "Infilteration               68236\n",
      "DoS attacks-GoldenEye       41508\n",
      "DoS attacks-Slowloris       10990\n",
      "Brute Force -Web              362\n",
      "Brute Force -XSS              151\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úÖ No Anomalous Label Entries Found!\n",
      "\n",
      "‚ö†Ô∏è Duplicate Rows Found: 8088\n",
      "\n",
      "‚úÖ Backup created at: C:\\Users\\S569652\\Documents\\INADS\\data\\Backup-Merged-Dataset-Final.csv\n",
      "\n",
      "üöÄ Next Steps to Consider:\n",
      "1Ô∏è‚É£ Feature Selection: Identify the most important features for training.\n",
      "2Ô∏è‚É£ Data Normalization: Ensure all numerical features are scaled appropriately.\n",
      "3Ô∏è‚É£ Data Balancing: Address class imbalance if needed.\n",
      "\n",
      "‚úÖ Dataset Inspection & Backup Complete! üéØ Ready for Next Steps.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# ‚úÖ Load the cleaned dataset\n",
    "file_path = \"C:\\\\Users\\\\S569652\\\\Documents\\\\INADS\\\\data\\\\Merged-Dataset-Final.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# üîç Step 1: Basic Dataset Information\n",
    "print(\"\\n‚úÖ Dataset Overview\")\n",
    "print(f\"Shape: {df.shape}\")  # Rows and columns\n",
    "print(f\"Total Columns: {len(df.columns)}\")\n",
    "print(\"\\nüîç Data Types Summary:\\n\", df.dtypes.value_counts())  # Check dtype distribution\n",
    "\n",
    "# üîç Step 2: Check for Missing Values\n",
    "missing_values = df.isnull().sum()\n",
    "total_missing = missing_values.sum()\n",
    "if total_missing > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è Total Missing Values: {total_missing}\")\n",
    "    print(\"\\nüîç Columns with Missing Values:\\n\", missing_values[missing_values > 0])\n",
    "else:\n",
    "    print(\"\\n‚úÖ No Missing Values Found!\")\n",
    "\n",
    "# üîç Step 3: Label Distribution\n",
    "print(\"\\nüîç Final Label Distribution:\")\n",
    "print(df[\"Label\"].value_counts())\n",
    "\n",
    "# üîç Step 4: Detect Anomalous Rows (like 'Label' in the Label column)\n",
    "if \"Label\" in df[\"Label\"].unique():\n",
    "    print(\"\\n‚ö†Ô∏è Anomalous Entries Found with Label 'Label':\")\n",
    "    print(df[df[\"Label\"] == \"Label\"])\n",
    "else:\n",
    "    print(\"\\n‚úÖ No Anomalous Label Entries Found!\")\n",
    "\n",
    "# üîç Step 5: Check for Duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "if duplicates > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è Duplicate Rows Found: {duplicates}\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ No Duplicates Found!\")\n",
    "\n",
    "# ‚úÖ Step 6: Backup the Final Dataset (Avoid Reprocessing)\n",
    "backup_path = \"C:\\\\Users\\\\S569652\\\\Documents\\\\INADS\\\\data\\\\Backup-Merged-Dataset-Final.csv\"\n",
    "shutil.copy(file_path, backup_path)\n",
    "print(f\"\\n‚úÖ Backup created at: {backup_path}\")\n",
    "\n",
    "# üîç Step 7: Decide Next Steps\n",
    "print(\"\\nüöÄ Next Steps to Consider:\")\n",
    "print(\"1Ô∏è‚É£ Feature Selection: Identify the most important features for training.\")\n",
    "print(\"2Ô∏è‚É£ Data Normalization: Ensure all numerical features are scaled appropriately.\")\n",
    "print(\"3Ô∏è‚É£ Data Balancing: Address class imbalance if needed.\")\n",
    "\n",
    "print(\"\\n‚úÖ Dataset Inspection & Backup Complete! üéØ Ready for Next Steps.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5322787f-c4ca-4350-bdeb-ea767476a704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset Loaded - Shape: (2278405, 80)\n",
      "\n",
      "üîç Column Names & Data Types:\n",
      "Dst Port         float64\n",
      "Protocol         float64\n",
      "Timestamp         object\n",
      "Flow Duration    float64\n",
      "Tot Fwd Pkts     float64\n",
      "                  ...   \n",
      "Idle Mean        float64\n",
      "Idle Std         float64\n",
      "Idle Max         float64\n",
      "Idle Min         float64\n",
      "Label             object\n",
      "Length: 80, dtype: object\n",
      "\n",
      "üîç Missing Values Per Column:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "üîç Unique Labels & Counts:\n",
      "Label\n",
      "Benign                    1580967\n",
      "DDoS attacks-LOIC-HTTP     576191\n",
      "Infilteration               68236\n",
      "DoS attacks-GoldenEye       41508\n",
      "DoS attacks-Slowloris       10990\n",
      "Brute Force -Web              362\n",
      "Brute Force -XSS              151\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚ö†Ô∏è Duplicate Rows: 8088\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# üìå Load the dataset\n",
    "file_path = \"C:\\\\Users\\\\S569652\\\\Documents\\\\INADS\\\\data\\\\Merged-Dataset-Final.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# üìå Display basic dataset information\n",
    "print(f\"‚úÖ Dataset Loaded - Shape: {df.shape}\")\n",
    "print(\"\\nüîç Column Names & Data Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# üìå Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"\\nüîç Missing Values Per Column:\")\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# üìå Check unique labels\n",
    "print(\"\\nüîç Unique Labels & Counts:\")\n",
    "print(df[\"Label\"].value_counts())\n",
    "\n",
    "# üìå Check for duplicate rows\n",
    "duplicate_rows = df.duplicated().sum()\n",
    "print(f\"\\n‚ö†Ô∏è Duplicate Rows: {duplicate_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "65b72179-729b-4b27-b4eb-616dd41e2e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Total Identical Duplicates Found: 15292\n",
      "\n",
      "üîç Sample Duplicate Rows:\n",
      "     Dst Port  Protocol            Timestamp  Flow Duration  Tot Fwd Pkts  \\\n",
      "42    49689.0       6.0  28/02/2018 08:25:11            1.0           2.0   \n",
      "53      443.0       6.0  28/02/2018 08:25:42          128.0           2.0   \n",
      "55      443.0       6.0  28/02/2018 08:26:06          250.0           2.0   \n",
      "188   49853.0       6.0  28/02/2018 08:31:22            1.0           2.0   \n",
      "213     443.0       6.0  28/02/2018 08:32:46          128.0           2.0   \n",
      "245   49832.0       6.0  28/02/2018 08:34:06            1.0           2.0   \n",
      "293   49903.0       6.0  28/02/2018 08:36:12           20.0           2.0   \n",
      "315   49894.0       6.0  28/02/2018 08:37:05            1.0           2.0   \n",
      "316   49889.0       6.0  28/02/2018 08:37:05            1.0           2.0   \n",
      "325   49902.0       6.0  28/02/2018 08:37:06            1.0           2.0   \n",
      "\n",
      "     Tot Bwd Pkts  TotLen Fwd Pkts  TotLen Bwd Pkts  Fwd Pkt Len Max  \\\n",
      "42            0.0              0.0              0.0              0.0   \n",
      "53            0.0              0.0              0.0              0.0   \n",
      "55            0.0              0.0              0.0              0.0   \n",
      "188           0.0              0.0              0.0              0.0   \n",
      "213           0.0              0.0              0.0              0.0   \n",
      "245           0.0              0.0              0.0              0.0   \n",
      "293           0.0              0.0              0.0              0.0   \n",
      "315           0.0              0.0              0.0              0.0   \n",
      "316           0.0              0.0              0.0              0.0   \n",
      "325           0.0              0.0              0.0              0.0   \n",
      "\n",
      "     Fwd Pkt Len Min  ...  Fwd Seg Size Min  Active Mean  Active Std  \\\n",
      "42               0.0  ...              20.0          0.0         0.0   \n",
      "53               0.0  ...              20.0          0.0         0.0   \n",
      "55               0.0  ...              20.0          0.0         0.0   \n",
      "188              0.0  ...              20.0          0.0         0.0   \n",
      "213              0.0  ...              20.0          0.0         0.0   \n",
      "245              0.0  ...              20.0          0.0         0.0   \n",
      "293              0.0  ...              20.0          0.0         0.0   \n",
      "315              0.0  ...              20.0          0.0         0.0   \n",
      "316              0.0  ...              20.0          0.0         0.0   \n",
      "325              0.0  ...              20.0          0.0         0.0   \n",
      "\n",
      "     Active Max  Active Min  Idle Mean  Idle Std  Idle Max  Idle Min   Label  \n",
      "42          0.0         0.0        0.0       0.0       0.0       0.0  Benign  \n",
      "53          0.0         0.0        0.0       0.0       0.0       0.0  Benign  \n",
      "55          0.0         0.0        0.0       0.0       0.0       0.0  Benign  \n",
      "188         0.0         0.0        0.0       0.0       0.0       0.0  Benign  \n",
      "213         0.0         0.0        0.0       0.0       0.0       0.0  Benign  \n",
      "245         0.0         0.0        0.0       0.0       0.0       0.0  Benign  \n",
      "293         0.0         0.0        0.0       0.0       0.0       0.0  Benign  \n",
      "315         0.0         0.0        0.0       0.0       0.0       0.0  Benign  \n",
      "316         0.0         0.0        0.0       0.0       0.0       0.0  Benign  \n",
      "325         0.0         0.0        0.0       0.0       0.0       0.0  Benign  \n",
      "\n",
      "[10 rows x 80 columns]\n"
     ]
    }
   ],
   "source": [
    "# Count the exact duplicate rows (all columns match)\n",
    "duplicate_rows = df[df.duplicated(keep=False)]  # Keep=False shows all duplicates, not just first occurrence\n",
    "print(f\"üîç Total Identical Duplicates Found: {duplicate_rows.shape[0]}\")\n",
    "\n",
    "# Display a sample of duplicate rows for verification\n",
    "print(\"\\nüîç Sample Duplicate Rows:\")\n",
    "print(duplicate_rows.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3543f1c3-51cf-4e46-8d60-32d776de19ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset Loaded Successfully!\n",
      "üìä Dataset Shape: (2278405, 80)\n",
      "üìå Total Columns: 80\n",
      "\n",
      "‚úÖ No Missing Values Found!\n",
      "\n",
      "üîç Final Label Distribution:\n",
      "Label\n",
      "Benign                    1580967\n",
      "DDoS attacks-LOIC-HTTP     576191\n",
      "Infilteration               68236\n",
      "DoS attacks-GoldenEye       41508\n",
      "DoS attacks-Slowloris       10990\n",
      "Brute Force -Web              362\n",
      "Brute Force -XSS              151\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "üîç Data Types Summary:\n",
      "\n",
      "float64    78\n",
      "object      2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üîç Sample Data (5 Random Rows):\n",
      "                   Dst Port           Protocol            Timestamp  \\\n",
      "874177   80.000000000000000  6.000000000000000  20/02/2018 10:20:03   \n",
      "2251056 443.000000000000000  6.000000000000000  23/02/2018 11:30:49   \n",
      "551241   53.000000000000000 17.000000000000000  28/02/2018 10:06:09   \n",
      "404695   53.000000000000000 17.000000000000000  28/02/2018 08:22:10   \n",
      "595507   53.000000000000000 17.000000000000000  28/02/2018 03:56:23   \n",
      "\n",
      "                    Flow Duration       Tot Fwd Pkts       Tot Bwd Pkts  \\\n",
      "874177   41085796.000000000000000  2.000000000000000  0.000000000000000   \n",
      "2251056 117747982.000000000000000 17.000000000000000 17.000000000000000   \n",
      "551241       1237.000000000000000  1.000000000000000  1.000000000000000   \n",
      "404695       1829.000000000000000  1.000000000000000  1.000000000000000   \n",
      "595507      12666.000000000000000  1.000000000000000  1.000000000000000   \n",
      "\n",
      "             TotLen Fwd Pkts      TotLen Bwd Pkts     Fwd Pkt Len Max  \\\n",
      "874177     0.000000000000000    0.000000000000000   0.000000000000000   \n",
      "2251056 2261.000000000000000 3606.000000000000000 945.000000000000000   \n",
      "551241    36.000000000000000  223.000000000000000  36.000000000000000   \n",
      "404695    35.000000000000000  127.000000000000000  35.000000000000000   \n",
      "595507    40.000000000000000  105.000000000000000  40.000000000000000   \n",
      "\n",
      "           Fwd Pkt Len Min  ...   Fwd Seg Size Min            Active Mean  \\\n",
      "874177   0.000000000000000  ... 20.000000000000000      0.000000000000000   \n",
      "2251056  0.000000000000000  ... 20.000000000000000 501800.000000000000000   \n",
      "551241  36.000000000000000  ...  8.000000000000000      0.000000000000000   \n",
      "404695  35.000000000000000  ...  8.000000000000000      0.000000000000000   \n",
      "595507  40.000000000000000  ...  8.000000000000000      0.000000000000000   \n",
      "\n",
      "                    Active Std             Active Max            Active Min  \\\n",
      "874177       0.000000000000000      0.000000000000000     0.000000000000000   \n",
      "2251056 622253.967444162000902 941800.000000000000000 61800.000000000000000   \n",
      "551241       0.000000000000000      0.000000000000000     0.000000000000000   \n",
      "404695       0.000000000000000      0.000000000000000     0.000000000000000   \n",
      "595507       0.000000000000000      0.000000000000000     0.000000000000000   \n",
      "\n",
      "                       Idle Mean               Idle Std  \\\n",
      "874177  41100000.000000000000000      0.000000000000000   \n",
      "2251056 58341300.500000000000000 394820.849450102017727   \n",
      "551241         0.000000000000000      0.000000000000000   \n",
      "404695         0.000000000000000      0.000000000000000   \n",
      "595507         0.000000000000000      0.000000000000000   \n",
      "\n",
      "                        Idle Max                 Idle Min  \\\n",
      "874177  41100000.000000000000000 41100000.000000000000000   \n",
      "2251056 58620481.000000000000000 58062120.000000000000000   \n",
      "551241         0.000000000000000        0.000000000000000   \n",
      "404695         0.000000000000000        0.000000000000000   \n",
      "595507         0.000000000000000        0.000000000000000   \n",
      "\n",
      "                          Label  \n",
      "874177   DDoS attacks-LOIC-HTTP  \n",
      "2251056                  Benign  \n",
      "551241                   Benign  \n",
      "404695                   Benign  \n",
      "595507                   Benign  \n",
      "\n",
      "[5 rows x 80 columns]\n",
      "‚úÖ Final Dataset Shape: (2278405, 80)\n",
      "‚úÖ Total Columns: 80\n",
      "\n",
      "‚ö†Ô∏è Warning: 8088 Duplicate Rows Still Present!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned dataset (Modify path if necessary)\n",
    "file_path = \"C:\\\\Users\\\\S569652\\\\Documents\\\\INADS\\\\data\\\\Merged-Dataset-Final.csv\"\n",
    "df_cleaned = pd.read_csv(file_path)\n",
    "\n",
    "print(\"‚úÖ Dataset Loaded Successfully!\")\n",
    "print(f\"üìä Dataset Shape: {df_cleaned.shape}\")\n",
    "print(f\"üìå Total Columns: {len(df_cleaned.columns)}\\n\")\n",
    "\n",
    "# 1Ô∏è‚É£ Missing Values Check\n",
    "missing_values = df_cleaned.isnull().sum()\n",
    "missing_summary = missing_values[missing_values > 0]\n",
    "\n",
    "if missing_summary.empty:\n",
    "    print(\"‚úÖ No Missing Values Found!\\n\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Missing Values Present:\")\n",
    "    print(missing_summary, \"\\n\")\n",
    "\n",
    "# 2Ô∏è‚É£ Label Distribution Check\n",
    "print(\"üîç Final Label Distribution:\")\n",
    "print(df_cleaned[\"Label\"].value_counts(), \"\\n\")\n",
    "\n",
    "# 3Ô∏è‚É£ Data Types & Structure Check\n",
    "print(\"üîç Data Types Summary:\\n\")\n",
    "print(df_cleaned.dtypes.value_counts())  # Ensures correct numerical/object types\n",
    "\n",
    "print(\"\\nüîç Sample Data (5 Random Rows):\")\n",
    "print(df_cleaned.sample(5))  # View random sample rows\n",
    "\n",
    "# 4Ô∏è‚É£ Confirm Dataset Shape & Columns\n",
    "print(f\"‚úÖ Final Dataset Shape: {df_cleaned.shape}\")  # Confirm expected row count\n",
    "print(f\"‚úÖ Total Columns: {len(df_cleaned.columns)}\\n\")  # Ensure 80 columns remain\n",
    "\n",
    "# 5Ô∏è‚É£ Detect Any Remaining Duplicates\n",
    "duplicate_count = df_cleaned.duplicated().sum()\n",
    "if duplicate_count == 0:\n",
    "    print(\"‚úÖ No Remaining Duplicate Rows!\\n\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Warning: {duplicate_count} Duplicate Rows Still Present!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da2fa0fd-21d5-4a60-bf08-386b42bc8b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Duplicates Removed! New Dataset Shape: (2270317, 80)\n",
      "\n",
      "üîç Final Label Distribution:\n",
      " Label\n",
      "Benign                    1573665\n",
      "DDoS attacks-LOIC-HTTP     576175\n",
      "Infilteration               68224\n",
      "DoS attacks-GoldenEye       41455\n",
      "DoS attacks-Slowloris       10285\n",
      "Brute Force -Web              362\n",
      "Brute Force -XSS              151\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop completely identical duplicates\n",
    "df_cleaned = df.drop_duplicates()\n",
    "\n",
    "# Save the cleaned dataset\n",
    "cleaned_file_path = \"C:\\\\Users\\\\S569652\\\\Documents\\\\INADS\\\\data\\\\Merged-Dataset-Final.csv\"\n",
    "df_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "# Display updated stats\n",
    "print(f\"‚úÖ Duplicates Removed! New Dataset Shape: {df_cleaned.shape}\")\n",
    "print(\"\\nüîç Final Label Distribution:\\n\", df_cleaned[\"Label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee2379a-1ef8-4fbd-8158-12266c9f85fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
