{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14ad9872-e639-4ca4-bd8e-ac463033775a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 21:33:41,006 - INFO - Loading dataset for Device Layer...\n",
      "2025-03-17 21:33:51,385 - INFO - Encoding labels...\n",
      "2025-03-17 21:33:52,042 - INFO - Building Autoencoder for Device Layer...\n",
      "2025-03-17 21:33:52,224 - INFO - Training Autoencoder...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m14190/14190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 491us/step - loss: 0.0265 - val_loss: 0.0012\n",
      "Epoch 2/20\n",
      "\u001b[1m14190/14190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 491us/step - loss: 0.0017 - val_loss: 2.6630e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m14190/14190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 497us/step - loss: 9.3465e-04 - val_loss: 8.7764e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m14190/14190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 473us/step - loss: 8.4828e-04 - val_loss: 2.6690e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m14190/14190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 491us/step - loss: 6.2839e-04 - val_loss: 0.0014\n",
      "Epoch 6/20\n",
      "\u001b[1m14190/14190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 476us/step - loss: 3.7729e-04 - val_loss: 7.6398e-05\n",
      "Epoch 7/20\n",
      "\u001b[1m14190/14190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 500us/step - loss: 3.7583e-04 - val_loss: 9.4411e-05\n",
      "Epoch 8/20\n",
      "\u001b[1m14190/14190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 475us/step - loss: 3.4056e-04 - val_loss: 0.0013\n",
      "Epoch 9/20\n",
      "\u001b[1m14190/14190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 491us/step - loss: 3.9021e-04 - val_loss: 1.8247e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m14190/14190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 478us/step - loss: 2.7956e-04 - val_loss: 1.2144e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m14190/14190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 491us/step - loss: 2.7927e-04 - val_loss: 2.4862e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m14190/14190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 486us/step - loss: 2.3454e-04 - val_loss: 2.9491e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m14190/14190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 493us/step - loss: 2.1351e-04 - val_loss: 7.1547e-05\n",
      "Epoch 14/20\n",
      "\u001b[1m14190/14190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 484us/step - loss: 2.0541e-04 - val_loss: 4.7623e-05\n",
      "Epoch 15/20\n",
      "\u001b[1m14190/14190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 489us/step - loss: 2.3480e-04 - val_loss: 2.5157e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m14190/14190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 493us/step - loss: 1.8380e-04 - val_loss: 9.9692e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m14190/14190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 478us/step - loss: 1.8410e-04 - val_loss: 8.7073e-05\n",
      "Epoch 18/20\n",
      "\u001b[1m14190/14190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 492us/step - loss: 1.5787e-04 - val_loss: 1.2850e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m14190/14190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 501us/step - loss: 1.8735e-04 - val_loss: 1.4722e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m14190/14190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 504us/step - loss: 1.4597e-04 - val_loss: 4.4923e-05\n",
      "\u001b[1m56758/56758\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 170us/step\n",
      "\u001b[1m14190/14190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 164us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 21:36:33,290 - INFO - Building GRU model for Device Layer...\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2025-03-17 21:36:33,321 - INFO - Training Device Layer GRU model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m28379/28379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 735us/step - accuracy: 0.9630 - loss: 0.1097 - val_accuracy: 0.9697 - val_loss: 0.0705\n",
      "Epoch 2/30\n",
      "\u001b[1m28379/28379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 736us/step - accuracy: 0.9697 - loss: 0.0724 - val_accuracy: 0.9698 - val_loss: 0.0714\n",
      "Epoch 3/30\n",
      "\u001b[1m28379/28379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 760us/step - accuracy: 0.9699 - loss: 0.0708 - val_accuracy: 0.9698 - val_loss: 0.0687\n",
      "Epoch 4/30\n",
      "\u001b[1m28379/28379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 761us/step - accuracy: 0.9696 - loss: 0.0707 - val_accuracy: 0.9698 - val_loss: 0.0691\n",
      "Epoch 5/30\n",
      "\u001b[1m28379/28379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 774us/step - accuracy: 0.9699 - loss: 0.0698 - val_accuracy: 0.9698 - val_loss: 0.0682\n",
      "Epoch 6/30\n",
      "\u001b[1m28379/28379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 767us/step - accuracy: 0.9697 - loss: 0.0700 - val_accuracy: 0.9697 - val_loss: 0.0690\n",
      "Epoch 7/30\n",
      "\u001b[1m28379/28379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 769us/step - accuracy: 0.9696 - loss: 0.0697 - val_accuracy: 0.9698 - val_loss: 0.0680\n",
      "Epoch 8/30\n",
      "\u001b[1m28379/28379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 790us/step - accuracy: 0.9697 - loss: 0.0694 - val_accuracy: 0.9698 - val_loss: 0.0680\n",
      "Epoch 9/30\n",
      "\u001b[1m28379/28379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 773us/step - accuracy: 0.9697 - loss: 0.0690 - val_accuracy: 0.9697 - val_loss: 0.0680\n",
      "Epoch 10/30\n",
      "\u001b[1m28379/28379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 768us/step - accuracy: 0.9699 - loss: 0.0691 - val_accuracy: 0.9699 - val_loss: 0.0676\n",
      "Epoch 11/30\n",
      "\u001b[1m28379/28379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 759us/step - accuracy: 0.9700 - loss: 0.0688 - val_accuracy: 0.9698 - val_loss: 0.0679\n",
      "Epoch 12/30\n",
      "\u001b[1m28379/28379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 757us/step - accuracy: 0.9696 - loss: 0.0694 - val_accuracy: 0.9698 - val_loss: 0.0678\n",
      "Epoch 13/30\n",
      "\u001b[1m28379/28379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 751us/step - accuracy: 0.9699 - loss: 0.0689 - val_accuracy: 0.9698 - val_loss: 0.0675\n",
      "Epoch 14/30\n",
      "\u001b[1m28379/28379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 761us/step - accuracy: 0.9698 - loss: 0.0690 - val_accuracy: 0.9698 - val_loss: 0.0674\n",
      "Epoch 15/30\n",
      "\u001b[1m28379/28379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 759us/step - accuracy: 0.9698 - loss: 0.0688 - val_accuracy: 0.9698 - val_loss: 0.0676\n",
      "Epoch 16/30\n",
      "\u001b[1m28379/28379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 752us/step - accuracy: 0.9699 - loss: 0.0686 - val_accuracy: 0.9698 - val_loss: 0.0678\n",
      "Epoch 17/30\n",
      "\u001b[1m28379/28379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 760us/step - accuracy: 0.9696 - loss: 0.0689 - val_accuracy: 0.9698 - val_loss: 0.0674\n",
      "Epoch 18/30\n",
      "\u001b[1m28379/28379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 762us/step - accuracy: 0.9699 - loss: 0.0684 - val_accuracy: 0.9698 - val_loss: 0.0676\n",
      "Epoch 19/30\n",
      "\u001b[1m28379/28379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 768us/step - accuracy: 0.9697 - loss: 0.0689 - val_accuracy: 0.9698 - val_loss: 0.0680\n",
      "Epoch 20/30\n",
      "\u001b[1m28379/28379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 762us/step - accuracy: 0.9697 - loss: 0.0688 - val_accuracy: 0.9698 - val_loss: 0.0676\n",
      "Epoch 21/30\n",
      "\u001b[1m28379/28379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 776us/step - accuracy: 0.9699 - loss: 0.0684 - val_accuracy: 0.9698 - val_loss: 0.0675\n",
      "Epoch 22/30\n",
      "\u001b[1m28379/28379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 777us/step - accuracy: 0.9698 - loss: 0.0685 - val_accuracy: 0.9698 - val_loss: 0.0675\n",
      "Epoch 23/30\n",
      "\u001b[1m28379/28379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 783us/step - accuracy: 0.9699 - loss: 0.0685 - val_accuracy: 0.9698 - val_loss: 0.0676\n",
      "Epoch 24/30\n",
      "\u001b[1m28379/28379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 770us/step - accuracy: 0.9696 - loss: 0.0687 - val_accuracy: 0.9698 - val_loss: 0.0673\n",
      "Epoch 25/30\n",
      "\u001b[1m28379/28379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 758us/step - accuracy: 0.9697 - loss: 0.0686 - val_accuracy: 0.9698 - val_loss: 0.0678\n",
      "Epoch 26/30\n",
      "\u001b[1m28379/28379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 768us/step - accuracy: 0.9697 - loss: 0.0687 - val_accuracy: 0.9698 - val_loss: 0.0675\n",
      "Epoch 27/30\n",
      "\u001b[1m28379/28379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 727us/step - accuracy: 0.9700 - loss: 0.0683 - val_accuracy: 0.9698 - val_loss: 0.0673\n",
      "Epoch 28/30\n",
      "\u001b[1m28379/28379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 733us/step - accuracy: 0.9699 - loss: 0.0681 - val_accuracy: 0.9698 - val_loss: 0.0675\n",
      "Epoch 29/30\n",
      "\u001b[1m28379/28379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 726us/step - accuracy: 0.9697 - loss: 0.0685 - val_accuracy: 0.9699 - val_loss: 0.0671\n",
      "Epoch 30/30\n",
      "\u001b[1m28379/28379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 714us/step - accuracy: 0.9698 - loss: 0.0683 - val_accuracy: 0.9699 - val_loss: 0.0671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 21:47:21,026 - INFO - GRU model training completed in 647.70 seconds.\n",
      "2025-03-17 21:47:21,026 - INFO - Evaluating Device Layer GRU model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14190/14190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 213us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2025-03-17 21:47:25,553 - INFO - \n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                Benign       0.96      1.00      0.98    314686\n",
      "      Brute Force -Web       0.88      0.88      0.88        67\n",
      "      Brute Force -XSS       0.93      0.84      0.89        32\n",
      "DDoS attacks-LOIC-HTTP       1.00      1.00      1.00    115275\n",
      " DoS attacks-GoldenEye       1.00      1.00      1.00      8273\n",
      " DoS attacks-Slowloris       1.00      1.00      1.00      2080\n",
      "         Infilteration       0.00      0.00      0.00     13651\n",
      "\n",
      "              accuracy                           0.97    454064\n",
      "             macro avg       0.82      0.82      0.82    454064\n",
      "          weighted avg       0.94      0.97      0.96    454064\n",
      "\n",
      "2025-03-17 21:47:25,584 - INFO - Model saved successfully at: /Users/akashthanneeru/Desktop/INADS_Data/Models/Device_Layer_AE_GRU.keras\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import logging\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, GRU, Dropout, BatchNormalization\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "# Define file paths\n",
    "DATASET_PATH = \"/Users/akashthanneeru/Desktop/INADS_Data/Data/Indexed_Dataset_Timestamp_Processed.csv\"\n",
    "MODEL_SAVE_PATH = \"/Users/akashthanneeru/Desktop/INADS_Data/Models/Device_Layer_AE_GRU.keras\"\n",
    "\n",
    "# Load dataset\n",
    "logging.info(\"Loading dataset for Device Layer...\")\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "\n",
    "# Define selected features for Device Layer\n",
    "device_features = [\n",
    "    \"Dst Port\", \"Fwd Pkts/s\", \"Bwd Pkts/s\",\n",
    "    \"Fwd Pkt Len Max\", \"Bwd Pkt Len Min\",\n",
    "    \"Init Fwd Win Byts\", \"Init Bwd Win Byts\",\n",
    "    \"Active Max\", \"Active Mean\", \"Active Min\", \"Idle Max\",\n",
    "    \"Hour\", \"Elapsed_Time\"\n",
    "]\n",
    "\n",
    "# Encode labels\n",
    "logging.info(\"Encoding labels...\")\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"Label\"] = label_encoder.fit_transform(df[\"Label\"])\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = df[device_features]\n",
    "y = df[\"Label\"]\n",
    "\n",
    "# Normalize the feature values\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Autoencoder model for feature extraction\n",
    "logging.info(\"Building Autoencoder for Device Layer...\")\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(64, activation=\"relu\")(input_layer)\n",
    "encoded = Dense(32, activation=\"relu\")(encoded)\n",
    "decoded = Dense(64, activation=\"relu\")(encoded)\n",
    "decoded = Dense(input_dim, activation=\"linear\")(decoded)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "# Train Autoencoder\n",
    "logging.info(\"Training Autoencoder...\")\n",
    "autoencoder.fit(X_train, X_train, epochs=20, batch_size=128, validation_data=(X_test, X_test), verbose=1)\n",
    "\n",
    "# Extract latent features\n",
    "encoder = Model(inputs=input_layer, outputs=encoded)\n",
    "X_train_encoded = encoder.predict(X_train)\n",
    "X_test_encoded = encoder.predict(X_test)\n",
    "\n",
    "# Reshape for GRU input\n",
    "X_train_encoded = X_train_encoded.reshape((X_train_encoded.shape[0], 1, X_train_encoded.shape[1]))\n",
    "X_test_encoded = X_test_encoded.reshape((X_test_encoded.shape[0], 1, X_test_encoded.shape[1]))\n",
    "\n",
    "# Define GRU model for final classification\n",
    "logging.info(\"Building GRU model for Device Layer...\")\n",
    "gru_model = Sequential([\n",
    "    GRU(32, return_sequences=False, input_shape=(1, X_train_encoded.shape[2])),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(len(label_encoder.classes_), activation=\"softmax\")  # Multi-class classification\n",
    "])\n",
    "\n",
    "# Compile GRU model\n",
    "gru_model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train GRU model\n",
    "logging.info(\"Training Device Layer GRU model...\")\n",
    "start_time = time.time()\n",
    "gru_model.fit(X_train_encoded, y_train, epochs=30, batch_size=64, validation_data=(X_test_encoded, y_test), verbose=1)\n",
    "training_time = time.time() - start_time\n",
    "logging.info(f\"GRU model training completed in {training_time:.2f} seconds.\")\n",
    "\n",
    "# Evaluate model\n",
    "logging.info(\"Evaluating Device Layer GRU model...\")\n",
    "y_pred = np.argmax(gru_model.predict(X_test_encoded), axis=1)\n",
    "report = classification_report(y_test, y_pred, target_names=label_encoder.classes_)\n",
    "logging.info(\"\\n\" + report)\n",
    "\n",
    "# Save the model in the recommended format\n",
    "gru_model.save(MODEL_SAVE_PATH)\n",
    "logging.info(f\"Model saved successfully at: {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0132654c-8a38-4b20-867e-3fadbbb723a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-17 22:48:24,574 - INFO - Loading dataset for Device Layer analysis...\n",
      "2025-03-17 22:48:38,356 - INFO - Loading Device Layer AE-GRU model...\n",
      "2025-03-17 22:48:38,846 - INFO - Extracting Autoencoder reconstruction errors...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m70948/70948\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 223us/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2270317,1,32) (2270317,7) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mabs(X \u001b[38;5;241m-\u001b[39m reconstructed), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     52\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting Autoencoder reconstruction errors...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 53\u001b[0m ae_reconstruction_errors \u001b[38;5;241m=\u001b[39m get_autoencoder_reconstruction_error(device_model, X_device)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# 🔹 Visualize Reconstruction Errors\u001b[39;00m\n\u001b[1;32m     56\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "Cell \u001b[0;32mIn[9], line 50\u001b[0m, in \u001b[0;36mget_autoencoder_reconstruction_error\u001b[0;34m(model, X)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03mComputes the reconstruction error for an autoencoder model.\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     49\u001b[0m reconstructed \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mabs(X \u001b[38;5;241m-\u001b[39m reconstructed), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2270317,1,32) (2270317,7) "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "# File Paths\n",
    "DEVICE_MODEL_PATH = \"/Users/akashthanneeru/Desktop/INADS_Data/Models/Device_Layer_AE_GRU.keras\"\n",
    "DATASET_PATH = \"/Users/akashthanneeru/Desktop/INADS_Data/Data/Indexed_Dataset_Timestamp_Processed.csv\"\n",
    "\n",
    "# Load Dataset\n",
    "logging.info(\"Loading dataset for Device Layer analysis...\")\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "\n",
    "# 🔹 Ensure we use the **correct** 32 features (Replace this with actual trained features)\n",
    "DEVICE_FEATURES = [\n",
    "    \"Dst Port\", \"Fwd Pkts/s\", \"Bwd Pkts/s\", \"Fwd Pkt Len Max\", \"Bwd Pkt Len Min\",\n",
    "    \"Init Fwd Win Byts\", \"Init Bwd Win Byts\", \"Active Max\", \"Active Min\",\n",
    "    \"Idle Max\", \"Hour\", \"Weekday\", \"Elapsed_Time\",\n",
    "    \"Flow Duration\", \"Flow Byts/s\", \"Flow Pkts/s\", \"Pkt Len Min\", \"Pkt Len Max\",\n",
    "    \"Fwd IAT Mean\", \"Bwd IAT Mean\", \"Down/Up Ratio\", \"Subflow Fwd Pkts\",\n",
    "    \"Active Mean\", \"Idle Mean\", \"Fwd Seg Size Avg\", \"Bwd Seg Size Avg\",\n",
    "    \"TotLen Fwd Pkts\", \"TotLen Bwd Pkts\", \"Flow IAT Mean\", \"Flow IAT Std\",\n",
    "    \"Init Fwd Win Byts\", \"Init Bwd Win Byts\"\n",
    "]\n",
    "\n",
    "# Standardize Features\n",
    "scaler = StandardScaler()\n",
    "df[DEVICE_FEATURES] = scaler.fit_transform(df[DEVICE_FEATURES])\n",
    "\n",
    "# Load Trained Device Layer Model\n",
    "logging.info(\"Loading Device Layer AE-GRU model...\")\n",
    "device_model = load_model(DEVICE_MODEL_PATH)\n",
    "\n",
    "# 🔹 Reshape Input to **match the model's expected shape**\n",
    "X_device = df[DEVICE_FEATURES].values.reshape(-1, 1, 32)  # (samples, time_steps=1, features=32)\n",
    "\n",
    "# ============== Autoencoder Reconstruction Error Analysis ==================\n",
    "def get_autoencoder_reconstruction_error(model, X):\n",
    "    \"\"\"\n",
    "    Computes the reconstruction error for an autoencoder model.\n",
    "    \"\"\"\n",
    "    reconstructed = model.predict(X)\n",
    "    return np.mean(np.abs(X - reconstructed), axis=1)\n",
    "\n",
    "logging.info(\"Extracting Autoencoder reconstruction errors...\")\n",
    "ae_reconstruction_errors = get_autoencoder_reconstruction_error(device_model, X_device)\n",
    "\n",
    "# 🔹 Visualize Reconstruction Errors\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(ae_reconstruction_errors, bins=50, kde=True, color='red')\n",
    "plt.title(\"Reconstruction Error Distribution - Device Layer\")\n",
    "plt.show()\n",
    "\n",
    "# ============== GRU Activation Analysis ==================\n",
    "def get_gru_hidden_states(model, X):\n",
    "    \"\"\"\n",
    "    Extracts hidden states from the first GRU layer.\n",
    "    \"\"\"\n",
    "    extractor = tf.keras.Model(inputs=model.input, outputs=model.layers[1].output)  # Extracting GRU layer\n",
    "    return extractor.predict(X)\n",
    "\n",
    "logging.info(\"Extracting GRU hidden states...\")\n",
    "gru_hidden_states = get_gru_hidden_states(device_model, X_device)\n",
    "\n",
    "# 🔹 Visualize GRU Hidden State Evolution\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(gru_hidden_states.mean(axis=0).reshape(1, -1), cmap='coolwarm')\n",
    "plt.title(\"GRU Hidden State Evolution - Device Layer\")\n",
    "plt.show()\n",
    "\n",
    "# ============== Correlation Heatmap ==================\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(df[DEVICE_FEATURES].corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Heatmap - Device Layer Features\")\n",
    "plt.show()\n",
    "\n",
    "# ============== Time-Series Feature Trends ==================\n",
    "plt.figure(figsize=(12, 6))\n",
    "for feature in DEVICE_FEATURES[:5]:  # Visualizing first 5 features\n",
    "    plt.plot(df[feature][:200], label=feature)\n",
    "plt.legend()\n",
    "plt.title(\"Time-Series Trends - First 5 Features (Device Layer)\")\n",
    "plt.show()\n",
    "\n",
    "logging.info(\"Device Layer analysis complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1908bb96-ed58-49c4-aaf5-db010da6d91f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
